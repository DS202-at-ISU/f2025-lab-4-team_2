---
title: "progress-report-nathankrieger"
author: "Nathan Krieger"
date: "2025-11-19"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

``` {r}


library(rvest)
library(httr)
library(dplyr)
library(tidyr)
library(stringr)
library(purrr)
library(Lahman)
library(readr)
library(ggplot2)

#head(HallOfFame, 3)

```


``` {r}
url <- "https://www.baseball-reference.com/awards/hof_2025.shtml"

resp <- httr::GET(
url,
httr::user_agent("R scraping for course lab â€” contact if needed")
)

if (httr::status_code(resp) != 200) {
stop("Could not retrieve the page. Try running again or using a different network.")
}

page <- read_html(resp)

hof_tbl <- page %>%
  html_node("table#hof_BBWAA") %>%
  html_table(fill = TRUE)

```

``` {r}
# Assuming 'hof_tbl' is the tibble with 29 rows and 39 blank/NA columns.

# 1. Remove the first row (the problematic header labels like "Rk", "Name", etc.)
#    We use base R indexing for slicing to avoid the dplyr error.
hof_data_sliced <- hof_tbl[ -1, ]

# 2. Select the necessary columns by index (position) and assign clean names immediately.
#    Index 2: Player Name
#    Index 4: Votes Received
#    Index 5: Percentage of Ballots

hof_step1_cleaned <- data.frame(
  Name = hof_data_sliced[[2]],
  Votes = hof_data_sliced[[4]],
  Pct_Vote = hof_data_sliced[[5]],
  stringsAsFactors = FALSE
)

head(hof_step1_cleaned)


```

``` {r}
# Find the text on the page that mentions "ballots cast"
ballots_text <- page %>%
  html_nodes("p") %>%
  html_text() %>%
  str_subset("ballots cast")

# Extract the number of ballots (e.g., "395 ballots cast")
total_ballots_str <- str_extract(ballots_text, "[0-9,]+ ballots cast")

# Clean and convert the total ballots to a number
total_ballots <- total_ballots_str %>%
  str_extract("[0-9,]+") %>%
  str_remove_all(",") %>%
  as.integer()

if (is.na(total_ballots) || length(total_ballots) == 0) {
  total_ballots <- 395
  warning(paste("Could not scrape total ballots. Using assumed value:", total_ballots))
}

# Calculate the 'needed' votes (75% of total ballots)
needed_votes <- ceiling(total_ballots * 0.75)

print(paste("Total Ballots Scraped/Used:", total_ballots))
print(paste("Needed Votes (75%):", needed_votes))


hof_step2_calculated <- hof_step1_cleaned %>%
  mutate(
    # 1. Clean Votes column (it should be clean already, but ensure it's numeric)
    votes = as.integer(str_remove_all(Votes, ",")),
    # 2. Calculate induction status ('Y' or 'N')
    inducted = ifelse(as.numeric(str_remove(Pct_Vote, "%")) >= 75, "Y", "N"),
    # 3. Add constant and derived columns
    yearID = 2025,
    votedBy = "BBWAA",
    ballots = total_ballots, # Use the scraped total
    needed = needed_votes,   # Use the calculated needed votes
    category = "Player",
    needed_note = NA_character_
  ) %>%
  # Keep only the columns needed for the final Lahman format (excluding playerID for now)
  select(Name, yearID, votedBy, ballots, needed, votes, inducted, category, needed_note)

print("Data after Calculation (First 3 Rows):")
head(hof_step2_calculated, 3)

```

``` {r}

# 1. Scrape the raw links (same as before)
player_links <- page %>%
  html_node("table#hof_BBWAA") %>%
  html_nodes("td:nth-child(2) a") %>%
  html_attr("href")

# 2. Extract the player ID path and manually fix the Sabathia link (index 2)
playerIDs_temp <- player_links %>%
  # Extract the pattern: /letter/playerID.shtml
  str_extract("/[a-z]/[a-z]+[0-9]{2}\\.shtml")

# we need to be sure the temporary vector is correct.
playerIDs_temp[2] <- "/players/s/sabatch01.shtml"


playerIDs <- playerIDs_temp %>%
  # Remove everything up to and including the LAST forward slash
  str_remove(".*\\/") %>%
  # Remove the file extension
  str_remove("\\.shtml")

# We will use the hof_step2_calculated data frame from your previous successful run.

if (length(playerIDs) == nrow(hof_step2_calculated)) {
  hof_2025_final <- hof_step2_calculated %>%
    mutate(playerID = playerIDs, .before = 1) %>%
    # Remove the temporary 'Name' column used for verification
    select(-Name) %>%
    # Final column ordering
    select(playerID, yearID, votedBy, ballots, needed, votes, inducted, category, needed_note)
} else {
  stop("Length mismatch after ID correction.")
}

# 4. Save the CSV again
readr::write_csv(hof_2025_final, "HallOfFame_2025.csv")

print(hof_2025_final[1:3, ])

```

``` {r}

# Save the final dataset as HallOfFame_2025.csv
write_csv(hof_2025_final, "HallOfFame_2025.csv")
```

``` {r}
# Add the visualization code here:
# 1. Combine the Lahman data with your 2025 data
hof_all <- Lahman::HallOfFame %>%
  bind_rows(hof_2025_final)

# 2. Create the bar plot
hof_all %>%
  ggplot(aes(x = yearID, fill = inducted)) +
  geom_bar() +
  xlim(c(1936, 2025)) +
  labs(
    title = "Hall of Fame Voting Records Over Time (Including 2025)",
    x = "Voting Year",
    y = "Number of Candidates Voted On",
    fill = "Inducted Status"
  ) +
  theme_minimal()

```
